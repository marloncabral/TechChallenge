# Plano de Deploy em ProduÃ§Ã£o - Dashboard e Modelo de PrevisÃ£o do PetrÃ³leo Brent

Este documento detalha o plano para deploy em produÃ§Ã£o do dashboard interativo e modelo de previsÃ£o do preÃ§o do petrÃ³leo Brent, garantindo disponibilidade, escalabilidade, seguranÃ§a e manutenÃ§Ã£o contÃ­nua.

## 1. Arquitetura da SoluÃ§Ã£o

### 1.1 Componentes Principais

- **Dashboard Streamlit**: Interface interativa para visualizaÃ§Ã£o de dados e previsÃµes
- **Modelo LSTM**: Modelo de Machine Learning para previsÃ£o do preÃ§o do petrÃ³leo
- **Banco de Dados**: Armazenamento dos dados histÃ³ricos e previsÃµes
- **Pipeline de AtualizaÃ§Ã£o**: Mecanismo para atualizaÃ§Ã£o automÃ¡tica dos dados e retreinamento do modelo

### 1.2 Diagrama de Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 â”‚     â”‚                 â”‚     â”‚                 â”‚
â”‚  Fonte de Dados â”‚â”€â”€â”€â”€â–¶â”‚  Pipeline ETL   â”‚â”€â”€â”€â”€â–¶â”‚  Banco de Dados â”‚
â”‚    (IPEA API)   â”‚     â”‚                 â”‚     â”‚                 â”‚
â”‚                 â”‚     â”‚                 â”‚     â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                         â”‚
                                                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 â”‚     â”‚                 â”‚     â”‚                 â”‚
â”‚    UsuÃ¡rios     â”‚â—€â”€â”€â”€â–¶â”‚    Dashboard    â”‚â—€â”€â”€â”€â–¶â”‚  Modelo LSTM    â”‚
â”‚                 â”‚     â”‚    Streamlit    â”‚     â”‚                 â”‚
â”‚                 â”‚     â”‚                 â”‚     â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 2. Infraestrutura

### 2.1 OpÃ§Ãµes de Hospedagem

#### OpÃ§Ã£o 1: Streamlit Cloud (Recomendada para MVP)
- **Vantagens**: Deploy rÃ¡pido, gerenciamento simplificado, integraÃ§Ã£o nativa com GitHub
- **Desvantagens**: LimitaÃ§Ãµes de personalizaÃ§Ã£o, recursos computacionais limitados
- **Custo estimado**: Gratuito para uso bÃ¡sico, $10-50/mÃªs para recursos adicionais

#### OpÃ§Ã£o 2: AWS/GCP/Azure
- **Vantagens**: Alta escalabilidade, flexibilidade, recursos computacionais robustos
- **Desvantagens**: ConfiguraÃ§Ã£o mais complexa, custo mais elevado
- **Custo estimado**: $50-200/mÃªs dependendo da configuraÃ§Ã£o

#### OpÃ§Ã£o 3: VPS Dedicado
- **Vantagens**: Controle total, custo previsÃ­vel
- **Desvantagens**: Gerenciamento manual, escalabilidade limitada
- **Custo estimado**: $20-100/mÃªs

### 2.2 Requisitos de Infraestrutura

- **CPU**: 2+ nÃºcleos para processamento do modelo
- **RAM**: MÃ­nimo 4GB, recomendado 8GB
- **Armazenamento**: 10GB para aplicaÃ§Ã£o, dados e modelo
- **Rede**: Largura de banda suficiente para mÃºltiplos usuÃ¡rios simultÃ¢neos

## 3. ContainerizaÃ§Ã£o com Docker

### 3.1 Estrutura do Dockerfile

```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Instalar dependÃªncias
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copiar arquivos da aplicaÃ§Ã£o
COPY . .

# Expor porta para o Streamlit
EXPOSE 8501

# Comando para iniciar a aplicaÃ§Ã£o
CMD ["streamlit", "run", "dashboard_com_modelo.py", "--server.port=8501", "--server.address=0.0.0.0"]
```

### 3.2 Docker Compose para Ambiente Completo

```yaml
version: '3'

services:
  dashboard:
    build: .
    ports:
      - "8501:8501"
    volumes:
      - ./dados_processados:/app/dados_processados
      - ./modelo:/app/modelo
    restart: always
    environment:
      - TZ=America/Sao_Paulo
```

## 4. Pipeline de Dados e AtualizaÃ§Ã£o do Modelo

### 4.1 AtualizaÃ§Ã£o de Dados

- **FrequÃªncia**: DiÃ¡ria (apÃ³s fechamento do mercado)
- **Fonte**: API do IPEA ou web scraping automatizado
- **Processo**:
  1. Coleta de novos dados
  2. ValidaÃ§Ã£o e limpeza
  3. IntegraÃ§Ã£o ao banco de dados histÃ³rico
  4. GeraÃ§Ã£o de novas features

### 4.2 Retreinamento do Modelo

- **FrequÃªncia**: Semanal ou mensal
- **Processo**:
  1. ExtraÃ§Ã£o dos dados atualizados
  2. Retreinamento do modelo LSTM
  3. AvaliaÃ§Ã£o de performance
  4. SubstituiÃ§Ã£o do modelo em produÃ§Ã£o se performance melhorar
  5. GeraÃ§Ã£o de novas previsÃµes

### 4.3 Script de AutomaÃ§Ã£o

```python
# pipeline_atualizacao.py
import os
import pandas as pd
from datetime import datetime
import subprocess
import logging

# Configurar logging
logging.basicConfig(
    filename='pipeline.log',
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

def atualizar_dados():
    """Atualiza os dados histÃ³ricos do petrÃ³leo Brent."""
    try:
        logging.info("Iniciando atualizaÃ§Ã£o de dados")
        # Executar script de coleta de dados
        subprocess.run(["python", "scraper_petroleo.py"], check=True)
        logging.info("Dados atualizados com sucesso")
        return True
    except Exception as e:
        logging.error(f"Erro na atualizaÃ§Ã£o de dados: {e}")
        return False

def retreinar_modelo():
    """Retreina o modelo LSTM com os dados atualizados."""
    try:
        logging.info("Iniciando retreinamento do modelo")
        # Executar script de treinamento do modelo
        subprocess.run(["python", "modelo_previsao.py"], check=True)
        logging.info("Modelo retreinado com sucesso")
        return True
    except Exception as e:
        logging.error(f"Erro no retreinamento do modelo: {e}")
        return False

def main():
    # Verificar dia da semana (1-7, onde 1 Ã© segunda-feira)
    dia_semana = datetime.now().isoweekday()
    
    # Atualizar dados diariamente
    sucesso_dados = atualizar_dados()
    
    # Retreinar modelo semanalmente (aos domingos)
    if dia_semana == 7 and sucesso_dados:
        retreinar_modelo()

if __name__ == "__main__":
    main()
```

## 5. SeguranÃ§a e Monitoramento

### 5.1 Medidas de SeguranÃ§a

- **HTTPS**: Configurar certificado SSL para comunicaÃ§Ã£o segura
- **AutenticaÃ§Ã£o**: Implementar sistema de login para acesso ao dashboard (opcional)
- **Backup**: Backup diÃ¡rio dos dados e modelos
- **Logs**: Registro detalhado de atividades e erros

### 5.2 Monitoramento

- **Performance da AplicaÃ§Ã£o**: Tempo de resposta, uso de recursos
- **Performance do Modelo**: MÃ©tricas de erro (RMSE, MAE, MAPE)
- **Alertas**: NotificaÃ§Ãµes para falhas na atualizaÃ§Ã£o de dados ou degradaÃ§Ã£o da performance do modelo

### 5.3 Ferramentas de Monitoramento

- **Prometheus/Grafana**: Para mÃ©tricas de infraestrutura
- **MLflow**: Para rastreamento de experimentos e versÃµes do modelo
- **Sentry**: Para monitoramento de erros em tempo real

## 6. Processo de Deploy

### 6.1 Deploy Inicial (MVP)

1. **PreparaÃ§Ã£o**:
   - Finalizar desenvolvimento e testes locais
   - Gerar arquivo `requirements.txt` com todas as dependÃªncias
   - Criar repositÃ³rio Git para versionamento

2. **Deploy no Streamlit Cloud**:
   - Conectar repositÃ³rio GitHub ao Streamlit Cloud
   - Configurar variÃ¡veis de ambiente necessÃ¡rias
   - Realizar deploy inicial

3. **ValidaÃ§Ã£o**:
   - Testar todas as funcionalidades no ambiente de produÃ§Ã£o
   - Verificar performance e tempo de resposta
   - Corrigir eventuais problemas

### 6.2 Deploy em Ambiente Corporativo (Fase 2)

1. **PreparaÃ§Ã£o da Infraestrutura**:
   - Provisionar servidor/VM conforme requisitos
   - Configurar rede, firewall e DNS

2. **ContainerizaÃ§Ã£o**:
   - Construir imagem Docker
   - Testar container localmente

3. **Deploy**:
   - Transferir imagem para servidor
   - Iniciar container com Docker Compose
   - Configurar proxy reverso (Nginx/Traefik) e SSL

4. **AutomaÃ§Ã£o**:
   - Configurar pipeline CI/CD para atualizaÃ§Ãµes automÃ¡ticas
   - Implementar scripts de atualizaÃ§Ã£o de dados e modelo

## 7. ManutenÃ§Ã£o e EvoluÃ§Ã£o

### 7.1 ManutenÃ§Ã£o Regular

- **AtualizaÃ§Ãµes de DependÃªncias**: Mensal
- **Backup de Dados**: DiÃ¡rio
- **RevisÃ£o de Performance**: Semanal
- **ValidaÃ§Ã£o de PrevisÃµes**: ComparaÃ§Ã£o mensal entre previsÃµes e valores reais

### 7.2 EvoluÃ§Ã£o Planejada

- **Fase 1 (MVP)**: Dashboard bÃ¡sico com modelo LSTM
- **Fase 2**: IncorporaÃ§Ã£o de variÃ¡veis exÃ³genas ao modelo
- **Fase 3**: ImplementaÃ§Ã£o de modelos ensemble para melhorar precisÃ£o
- **Fase 4**: AdiÃ§Ã£o de anÃ¡lises de cenÃ¡rios e simulaÃ§Ãµes

## 8. Requisitos para ProduÃ§Ã£o

### 8.1 Arquivo requirements.txt

```
streamlit==1.32.0
pandas==2.1.3
numpy==2.1.3
matplotlib==3.8.2
seaborn==0.13.1
plotly==5.18.0
tensorflow==2.19.0
scikit-learn==1.6.1
joblib==1.5.0
requests==2.31.0
beautifulsoup4==4.12.2
markdown==3.8
pillow==10.2.0
```

### 8.2 Estrutura de DiretÃ³rios

```
projeto_petroleo/
â”œâ”€â”€ dashboard_com_modelo.py     # AplicaÃ§Ã£o Streamlit principal
â”œâ”€â”€ modelo_previsao.py          # Script de treinamento do modelo
â”œâ”€â”€ scraper_petroleo.py         # Script de coleta de dados
â”œâ”€â”€ pipeline_atualizacao.py     # Script de automaÃ§Ã£o
â”œâ”€â”€ requirements.txt            # DependÃªncias
â”œâ”€â”€ Dockerfile                  # ConfiguraÃ§Ã£o do container
â”œâ”€â”€ docker-compose.yml          # ConfiguraÃ§Ã£o do ambiente
â”œâ”€â”€ README.md                   # DocumentaÃ§Ã£o
â”œâ”€â”€ dados_processados/          # Dados processados
â”‚   â”œâ”€â”€ petroleo_brent_processado.csv
â”‚   â”œâ”€â”€ eventos_importantes.csv
â”‚   â””â”€â”€ previsao_futura.csv
â”œâ”€â”€ modelo/                     # Artefatos do modelo
â”‚   â”œâ”€â”€ modelo_lstm.h5
â”‚   â”œâ”€â”€ scaler_X.pkl
â”‚   â”œâ”€â”€ scaler_y.pkl
â”‚   â”œâ”€â”€ parametros.pkl
â”‚   â””â”€â”€ metricas_por_horizonte.csv
â”œâ”€â”€ visualizacoes/              # Imagens e grÃ¡ficos
â””â”€â”€ documentacao/               # DocumentaÃ§Ã£o detalhada
    â””â”€â”€ documentacao_modelo.md
```

## 9. Estimativa de Custos

### 9.1 Custos Iniciais (MVP)

- **Streamlit Cloud**: $0-50/mÃªs
- **Desenvolvimento e Setup**: 40 horas de trabalho

### 9.2 Custos Mensais (Ambiente Corporativo)

- **Infraestrutura Cloud**: $50-200/mÃªs
- **ManutenÃ§Ã£o e Suporte**: 10 horas/mÃªs
- **AtualizaÃ§Ãµes e Melhorias**: 20 horas/mÃªs

## 10. Cronograma de ImplementaÃ§Ã£o

### 10.1 MVP (2-4 semanas)

- **Semana 1**: FinalizaÃ§Ã£o do desenvolvimento e testes locais
- **Semana 2**: Deploy no Streamlit Cloud e validaÃ§Ã£o
- **Semana 3**: Ajustes finais e documentaÃ§Ã£o
- **Semana 4**: Treinamento dos usuÃ¡rios e entrega

## 11. ConclusÃ£o

Este plano de deploy fornece um roteiro completo para colocar em produÃ§Ã£o o dashboard interativo e o modelo de previsÃ£o do preÃ§o do petrÃ³leo Brent. A abordagem em fases permite uma implementaÃ§Ã£o gradual, comeÃ§ando com um MVP no Streamlit Cloud e evoluindo para uma soluÃ§Ã£o corporativa robusta conforme necessÃ¡rio.

A soluÃ§Ã£o proposta equilibra facilidade de implementaÃ§Ã£o, custo e escalabilidade, permitindo que o cliente obtenha valor rapidamente enquanto mantÃ©m a flexibilidade para expansÃµes futuras.

        # TÃ­tulo acima do link
        st.subheader("Notebook utilizado inicialmente como teste de previsÃ£o")

        st.markdown(
        '<a href="(https://github.com/marloncabral/TechChallenge/blob/main/documentacao/plano_deploy.md)" target="_blank">ğŸ”— Acesse o notebook completo no GitHub</a>',
        unsafe_allow_html=True

